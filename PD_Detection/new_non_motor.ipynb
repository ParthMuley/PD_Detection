{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('COHORT_1_data.csv',usecols=['PATNO','ENROLL_AGE', 'SDMTOTAL', 'STAI_TOT', 'SFT_TOT', 'SCOPA_AUT_TOT',\n",
    "       'REMSLEEP_TOT', 'QUIP_A', 'QUIP_B', 'QUIP_C', 'QUIP_D', 'QUIP_E',\n",
    "       'MoCA_score', 'LNS_TOT', 'HVLT_TOT_Recall', 'HVLT_DCR_REC',\n",
    "       'HVLT_RETENTION', 'GDS_TOT', 'GDS_Depressed', 'ESS_TOT', 'ESS_Sleepy',\n",
    "       'BJLOT_TOT', 'COHORT'])\n",
    "df2 = pd.read_csv('COHORT_2_data.csv',usecols=['PATNO','ENROLL_AGE', 'SDMTOTAL', 'STAI_TOT', 'SFT_TOT', 'SCOPA_AUT_TOT',\n",
    "       'REMSLEEP_TOT', 'QUIP_A', 'QUIP_B', 'QUIP_C', 'QUIP_D', 'QUIP_E',\n",
    "       'MoCA_score', 'LNS_TOT', 'HVLT_TOT_Recall', 'HVLT_DCR_REC',\n",
    "       'HVLT_RETENTION', 'GDS_TOT', 'GDS_Depressed', 'ESS_TOT', 'ESS_Sleepy',\n",
    "       'BJLOT_TOT', 'COHORT'])\n",
    "df3 = pd.read_csv('COHORT_3_data.csv',usecols=['PATNO','ENROLL_AGE', 'SDMTOTAL', 'STAI_TOT', 'SFT_TOT', 'SCOPA_AUT_TOT',\n",
    "       'REMSLEEP_TOT', 'QUIP_A', 'QUIP_B', 'QUIP_C', 'QUIP_D', 'QUIP_E',\n",
    "       'MoCA_score', 'LNS_TOT', 'HVLT_TOT_Recall', 'HVLT_DCR_REC',\n",
    "       'HVLT_RETENTION', 'GDS_TOT', 'GDS_Depressed', 'ESS_TOT', 'ESS_Sleepy',\n",
    "       'BJLOT_TOT', 'COHORT'])\n",
    "df4 = pd.read_csv('COHORT_4_data.csv',usecols=['PATNO','ENROLL_AGE', 'SDMTOTAL', 'STAI_TOT', 'SFT_TOT', 'SCOPA_AUT_TOT',\n",
    "       'REMSLEEP_TOT', 'QUIP_A', 'QUIP_B', 'QUIP_C', 'QUIP_D', 'QUIP_E',\n",
    "       'MoCA_score', 'LNS_TOT', 'HVLT_TOT_Recall', 'HVLT_DCR_REC',\n",
    "       'HVLT_RETENTION', 'GDS_TOT', 'GDS_Depressed', 'ESS_TOT', 'ESS_Sleepy',\n",
    "       'BJLOT_TOT', 'COHORT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parkinson       ---->  1\n",
    "# Healthy Cntrols ---->  2\n",
    "# SWEDD           ---->  3\n",
    "# Prodromal       ---->  4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# Define a function to fill missing values and apply KNN imputation\n",
    "def fill_missing_and_impute(df):\n",
    "    # Group DataFrame by 'PATNO' and fill missing values with median within each group\n",
    "    grouped_df = df.groupby('PATNO').transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # Add 'PATNO' column back to the filled DataFrame\n",
    "    df_filled = pd.concat([df['PATNO'], grouped_df], axis=1)\n",
    "\n",
    "    # Calculate the mean of each feature after filling missing values\n",
    "    grouped_mean_df = df_filled.groupby('PATNO').mean().reset_index()\n",
    "\n",
    "    # Apply KNN imputation to handle remaining missing values\n",
    "    knn = KNNImputer()\n",
    "    grouped_mean_df = pd.DataFrame(knn.fit_transform(grouped_mean_df), columns=grouped_mean_df.columns)\n",
    "    \n",
    "    return grouped_mean_df\n",
    "\n",
    "# Apply the function to all four dataframes\n",
    "df1_filled = fill_missing_and_impute(df1)\n",
    "df2_filled = fill_missing_and_impute(df2)\n",
    "df3_filled = fill_missing_and_impute(df3)\n",
    "df4_filled = fill_missing_and_impute(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1_filled.shape   --->  1752\n",
    "# df2_filled.shape   --->  357\n",
    "# df3_filled.shape   --->  81\n",
    "# df4_filled.shape   ---> 1737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.concat([df1_filled,df2_filled,df3_filled,df4_filled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_quip = ['QUIP_A','QUIP_B','QUIP_C','QUIP_D','QUIP_E']\n",
    "\n",
    "f['QUIP_TOT'] = f[sum_quip].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_hvlt = ['HVLT_TOT_Recall', 'HVLT_DCR_REC','HVLT_RETENTION']\n",
    "f['HVLT_TOT'] = f[sum_hvlt].sum(axis=1)\n",
    "\n",
    "sum_gds = ['GDS_TOT', 'GDS_Depressed']\n",
    "f['NGDS_TOT'] = f[sum_gds].sum(axis=1)\n",
    "\n",
    "sum_ess = ['ESS_TOT', 'ESS_Sleepy']\n",
    "f['NESS_TOT'] = f[sum_ess].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PATNO', 'SDMTOTAL', 'STAI_TOT', 'SFT_TOT', 'SCOPA_AUT_TOT',\n",
       "       'REMSLEEP_TOT', 'QUIP_A', 'QUIP_B', 'QUIP_C', 'QUIP_D', 'QUIP_E',\n",
       "       'MoCA_score', 'LNS_TOT', 'HVLT_TOT_Recall', 'HVLT_DCR_REC',\n",
       "       'HVLT_RETENTION', 'GDS_TOT', 'GDS_Depressed', 'ESS_TOT', 'ESS_Sleepy',\n",
       "       'BJLOT_TOT', 'COHORT', 'ENROLL_AGE', 'QUIP_TOT', 'HVLT_TOT', 'NGDS_TOT',\n",
       "       'NESS_TOT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATNO              0.167667\n",
      "SDMTOTAL           0.179086\n",
      "STAI_TOT          -0.131191\n",
      "SFT_TOT           -0.043927\n",
      "SCOPA_AUT_TOT     -0.079901\n",
      "REMSLEEP_TOT       0.093612\n",
      "QUIP_A            -0.034002\n",
      "QUIP_B            -0.021331\n",
      "QUIP_C             0.011175\n",
      "QUIP_D             0.070924\n",
      "QUIP_E             0.012671\n",
      "MoCA_score         0.027158\n",
      "LNS_TOT            0.094343\n",
      "HVLT_TOT_Recall    0.047585\n",
      "HVLT_DCR_REC       0.036601\n",
      "HVLT_RETENTION     0.013834\n",
      "GDS_TOT           -0.129484\n",
      "GDS_Depressed     -0.092210\n",
      "ESS_TOT           -0.074476\n",
      "ESS_Sleepy        -0.078770\n",
      "BJLOT_TOT          0.069151\n",
      "COHORT             1.000000\n",
      "ENROLL_AGE         0.196641\n",
      "QUIP_TOT           0.028439\n",
      "HVLT_TOT           0.048521\n",
      "NGDS_TOT          -0.127065\n",
      "NESS_TOT          -0.075870\n",
      "Name: COHORT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = f.corr()\n",
    "\n",
    "# Get the correlation of 'cohort' with all other categories\n",
    "cohort_correlation = correlation_matrix['COHORT']\n",
    "\n",
    "print(cohort_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "f['COHORT'] = le.fit_transform(f['COHORT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  f.drop(['COHORT','PATNO','QUIP_A', 'QUIP_B', 'QUIP_C', 'QUIP_D', 'QUIP_E',\n",
    "             'HVLT_TOT_Recall', 'HVLT_DCR_REC','HVLT_RETENTION',\n",
    "             'GDS_TOT', 'GDS_Depressed', 'ESS_TOT', 'ESS_Sleepy'],axis=1)\n",
    "y= f['COHORT']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adasyn = ADASYN(sampling_strategy='auto',random_state=42)\n",
    "# X_adasyn, y_adasyn = adasyn.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_smote,y_smote, \n",
    "                                   random_state=104,  \n",
    "                                   test_size=0.25,  \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train_scaled = scaler.transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7351598173515982\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel=\"rbf\", gamma=\"auto\",probability=True)\n",
    "svm.fit(X_train,y_train)\n",
    "prediction = svm.predict(X_test)\n",
    "\n",
    "accuracy_SVM = accuracy_score(prediction, y_test)\n",
    "print(accuracy_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7248858447488584\n"
     ]
    }
   ],
   "source": [
    "dec = DecisionTreeClassifier(random_state=0)\n",
    "dec.fit(X_train,y_train)\n",
    "dec_pred = dec.predict(X_test)\n",
    "accuracy_DEC = accuracy_score(dec_pred, y_test)\n",
    "print(accuracy_DEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8127853881278538\n"
     ]
    }
   ],
   "source": [
    "rand = RandomForestClassifier(max_depth=15, random_state=0)\n",
    "rand.fit(X_train,y_train)\n",
    "rand_pred = rand.predict(X_test)\n",
    "rand_accuracy = accuracy_score(rand_pred,y_test)\n",
    "print(rand_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735730593607306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train,y_train)\n",
    "neigh_pred = neigh.predict(X_test)\n",
    "neigh_accuracy = accuracy_score(neigh_pred,y_test)\n",
    "print(neigh_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy: 0.757420091324201\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_train, X_test, y_train, and y_test are already defined\n",
    "\n",
    "# Initialize and train the gradient boosting classifier\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "gb_accuracy = accuracy_score(gb_pred, y_test)\n",
    "print(\"Gradient Boosting Classifier Accuracy:\", gb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# Create a Soft Voting Classifier\n",
    "labels = ['Decision Forest', 'Random Forest', 'GB','KNN']\n",
    "voting_clf_hard = VotingClassifier(\n",
    "\testimators=[\n",
    "        (labels[0], dec),\n",
    "\t\t(labels[1], rand), # Include the second classifier \n",
    "\t\t(labels[2],gb_clf),\n",
    "        # (labels[3], neigh), # Include the third classifier \n",
    "\t],\n",
    "\tvoting='hard' # Specify soft voting, where class probabilities are combined\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809931506849315\n"
     ]
    }
   ],
   "source": [
    "voting_clf_hard.fit(X_train,y_train)\n",
    "V_hard_pred = voting_clf_hard.predict(X_test)\n",
    "voting_hard_accuracy = accuracy_score(V_hard_pred,y_test)\n",
    "print(voting_hard_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (Accuracy): [0.69338422 0.67938931 0.67643312 0.68535032 0.70828025]\n",
      "Mean Accuracy: 0.688567446232638\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "cross_val_results = cross_val_score(voting_clf_hard, X, y, cv=kf)\n",
    "print(f'Cross-Validation Results (Accuracy): {cross_val_results}')\n",
    "print(f'Mean Accuracy: {cross_val_results.mean()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
